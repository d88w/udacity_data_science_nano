{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1.25664  2.04978  -6.23640   4.71926  -4.26931  0.20590\n",
      "0   -3.89012 -0.37511   6.14979   4.94585  -3.57844  0.00640\n",
      "1    5.09784  0.98120  -0.29939   5.85805   0.28297 -0.20626\n",
      "2    0.39034 -3.06861  -5.63488   6.43941   0.39256 -0.07084\n",
      "3    5.84727 -0.15922  11.41246   7.52165   1.69886  0.29022\n",
      "4   -2.86202 -0.84337  -1.08165   0.67115  -2.48911  0.52328\n",
      "5   -7.09328 -0.07233   6.76632  13.06072   0.12876 -0.01048\n",
      "6   -7.17614  0.62875  -2.89924  -5.21458  -2.70344 -0.22035\n",
      "7    8.67430  2.09933 -11.23591  -5.99532  -2.79770 -0.08710\n",
      "8   -6.03324 -4.16724   2.42063  -3.61827   1.96815  0.17723\n",
      "9    8.67485  1.48271  -1.31205  -1.81154   2.67940  0.04803\n",
      "10   4.36248 -2.69788  -4.60562  -0.12849   3.40617 -0.07841\n",
      "11   9.97205 -0.61515   2.63039   2.81044   5.68249 -0.04495\n",
      "12  -1.44556  0.18337   4.61021  -2.54824   0.86388  0.17696\n",
      "13  -3.90381  0.53243   2.83416  -5.42397  -0.06367 -0.22810\n",
      "14 -12.39824 -1.54269  -2.66748  10.82084   5.92054  0.13415\n",
      "15   5.75911 -0.82222  10.24701   0.33635   0.26025 -0.02588\n",
      "16  -7.12657  3.28707  -0.22508  13.42902   2.16708 -0.09153\n",
      "17   7.22736  1.27122   0.99188  -8.87118  -6.86533  0.09410\n",
      "18 -10.31393  2.23819  -7.87166  -3.44388  -1.43267 -0.07893\n",
      "19  -8.25971 -0.15799  -1.81740   1.12972   4.24165 -0.01607\n",
      "20  13.37454 -0.91051   4.61334   0.93989   4.81350 -0.07428\n",
      "21   1.49973 -0.50929  -2.66670  -1.28560  -0.18299 -0.00552\n",
      "22 -10.46766  0.73077   3.93791  -1.73489  -3.26768  0.02366\n",
      "23  -1.15898  3.14709  -4.73329  13.61355  -3.87487 -0.14112\n",
      "24   4.42275 -2.09867   3.06395  -0.45331  -2.07717  0.22815\n",
      "25  -3.34113 -0.31138   4.49844  -2.32619  -2.95757 -0.00793\n",
      "26  -1.85433 -1.32509   8.06274  12.75080  -0.89005 -0.04312\n",
      "27   0.85474 -0.50002  -3.52152  -4.30405   4.13943 -0.02834\n",
      "28   0.33271 -5.28025  -4.95832  22.48546   4.95051  0.17153\n",
      "29  -0.07308  0.51247  -1.38120   7.86552   3.31641  0.06808\n",
      "..       ...      ...       ...       ...       ...      ...\n",
      "69   2.03663 -0.49245   4.30331  17.83947  -0.96290  0.10803\n",
      "70  -1.72766  1.38544   1.88234  -0.58255  -1.55674  0.08176\n",
      "71  -2.40833 -0.00177   2.32146  -1.06438   2.92114 -0.05635\n",
      "72  -1.22998 -1.81632  -2.81740  12.29083  -1.40781 -0.15404\n",
      "73  -3.85332 -1.24892  -6.24187   0.95304  -3.66314  0.02746\n",
      "74  -7.18419 -0.91048  -2.41759   2.46251  -5.11125 -0.05417\n",
      "75   5.69279 -0.66299  -3.40195   1.77690   3.70297 -0.02102\n",
      "76   5.82082  1.75872   1.50493  -1.14792  -0.66104  0.14593\n",
      "77   0.98854 -0.91971  11.94650   1.36820   2.53711  0.30359\n",
      "78   1.55873  0.25462   2.37448  16.04402  -0.06938 -0.36479\n",
      "79  -0.66650 -2.27045   6.40325   7.64815   1.58676 -0.11790\n",
      "80   4.58728 -2.90732  -0.05803   2.27259   2.29507  0.13907\n",
      "81 -11.73607 -2.26595   1.63461   6.21257   0.73723  0.03777\n",
      "82  -2.03125  1.83364   1.57590   5.52329  -3.64759  0.06059\n",
      "83   4.63339  1.37232  -0.62675  13.46151   3.69937 -0.09897\n",
      "84  -0.93955 -1.39664  -4.69027  -5.30208  -2.70883  0.07360\n",
      "85   3.19531 -1.43186   3.82859  -9.83963  -2.83611  0.09403\n",
      "86  -0.66991 -0.33925  -0.26224  -6.71810   0.52439  0.00654\n",
      "87   3.32705 -0.20431  -0.61940  -5.82014  -3.30832 -0.13399\n",
      "88  -3.01400 -1.40133   7.13418 -15.85676   3.92442  0.29137\n",
      "89  10.75129 -0.08744   4.35843  -9.89202  -0.71794  0.12349\n",
      "90   4.74271 -1.32895  -2.73218   9.15129   0.93902 -0.17934\n",
      "91   3.96678 -1.93074  -1.98368 -12.52082   7.35129 -0.30941\n",
      "92   2.98664  1.85034   2.54075  -2.98750   0.37193  0.16048\n",
      "93  -6.73878 -1.08637  -1.55835  -3.93097  -3.02271  0.11860\n",
      "94  -4.58240 -1.27825   7.55098   8.83930  -3.80318  0.04386\n",
      "95 -10.00364  2.66002  -4.26776  -3.73792  -0.72349 -0.24617\n",
      "96  -4.32624 -2.30314  -8.16044   4.46366  -3.33569 -0.01655\n",
      "97  -1.90167 -0.15858 -10.43466   4.89762  -0.64606 -0.14519\n",
      "98   2.43213  2.41613   2.49949  -8.03891  -1.64164 -0.63444\n",
      "\n",
      "[99 rows x 6 columns]\n",
      "    12.31798\n",
      "0   23.67628\n",
      "1   -1.53459\n",
      "2  -24.68670\n",
      "3   17.54122\n",
      "4    9.39789\n",
      "5   11.73565\n",
      "6    4.42482\n",
      "7   -5.94615\n",
      "8  -13.11848\n",
      "9   -9.25647\n",
      "10 -29.94048\n",
      "11 -20.46775\n",
      "12   7.12822\n",
      "13   6.05628\n",
      "14 -32.91328\n",
      "15  17.75036\n",
      "16  -2.80277\n",
      "17  33.98791\n",
      "18  -3.18407\n",
      "19 -20.57366\n",
      "20 -12.66661\n",
      "21  -6.56370\n",
      "22  23.19621\n",
      "23  13.89143\n",
      "24  10.29282\n",
      "25  21.21512\n",
      "26  14.54248\n",
      "27 -24.77918\n",
      "28 -45.01710\n",
      "29 -12.63583\n",
      "..       ...\n",
      "69  10.85762\n",
      "70  16.49896\n",
      "71  -8.16292\n",
      "72  -6.76994\n",
      "73  -0.87206\n",
      "74  11.48350\n",
      "75 -23.71307\n",
      "76  11.82506\n",
      "77  13.23011\n",
      "78  -0.67043\n",
      "79  -3.12393\n",
      "80 -16.76419\n",
      "81  -7.00464\n",
      "82  23.96407\n",
      "83 -13.66325\n",
      "84  -0.26176\n",
      "85  14.30309\n",
      "86  -2.45750\n",
      "87   9.94820\n",
      "88  -0.19544\n",
      "89  12.68742\n",
      "90 -15.58698\n",
      "91 -40.20406\n",
      "92   9.08819\n",
      "93   6.24185\n",
      "94  26.14768\n",
      "95   0.76214\n",
      "96 -10.05262\n",
      "97 -19.63970\n",
      "98  12.76193\n",
      "\n",
      "[99 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assign the data to predictor and outcome variables\n",
    "# TODO: Load the data\n",
    "\n",
    "#1. Load in the data\n",
    "#The data is in the file called 'data.csv'. Note that there's no header row on this file.\n",
    "#Split the data so that the six predictor features (first six columns) are stored in X, \n",
    "#and the outcome feature (last column) is stored in y.\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/derekwang/Desktop/Python/udacity nano degree/data_regularization.csv\")\n",
    "X = train_data.iloc[:, 0:6]  #0 to 5 columns, 6 is not included. open bracket in python\n",
    "y = train_data.iloc[:, [6]]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derek's Notes: When Should I Use Feature Scaling?\n",
    "\n",
    "In many machine learning algorithms, the result will change depending on the units of your data. This is especially true in two specific cases:\n",
    "1. When your algorithm uses a distance-based metric to predict.\n",
    "2. When you incorporate regularization.\n",
    "\n",
    "Distance Based Metrics:\n",
    "In future lessons, you will see one common supervised learning technique that is based on the distance points are from one another called Support Vector Machines (or SVMs). Another technique that involves distance based methods to determine a prediction is k-nearest neighbors (or k-nn). With either of these techniques, choosing not to scale your data may lead to drastically different (and likely misleading) ending predictions.\n",
    "\n",
    "Regularization:\n",
    "When you start introducing regularization, you will again want to scale the features of your model. The penalty on particular coefficients in regularized linear regression techniques depends largely on the scale associated with the features. When one feature is on a small range, say from 0 to 10, and another is on a large range, say from 0 to 1 000 000, applying regularization is going to unfairly punish the feature with the small range. \n",
    "\n",
    "This means you will want to scale features any time you are applying regularization.\n",
    "\n",
    "see Feature Scaling workbook for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create the linear regression model with lasso regularization.\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          2.33659619  2.0140086  -0.05753445 -3.91583673  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Retrieve and print out the coefficients from the regression model.\n",
    "\n",
    "#Obtain the coefficients of the fit regression model using the .coef_ attribute of the Lasso object. \n",
    "#Store this in the reg_coef variable: the coefficients will be printed out, \n",
    "#and you will use your observations to answer the question at the bottom of the page.\n",
    "\n",
    "reg_coef = lasso_reg.coef_\n",
    "print(reg_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
